{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10901489,"sourceType":"datasetVersion","datasetId":6775341}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pickle\nimport os\n\nbase_path = \"/kaggle/input/wesad-full-dataset/WESAD/\"\nsubject_ids = [f\"S{i}\" for i in range(2, 18)]  # S2 to S17\nall_subjects_dfs = []\n\nfor subject_id in subject_ids:\n    txt_file = f\"{base_path}{subject_id}/{subject_id}_respiban.txt\"\n    pkl_file = f\"{base_path}{subject_id}/{subject_id}.pkl\"\n    \n    if not os.path.exists(txt_file) or not os.path.exists(pkl_file):\n        print(f\"Skipping {subject_id} - files not found\")\n        continue\n    \n    try:\n        # Load ECG\n        ecg_data = np.loadtxt(txt_file)\n        ecg_raw = ecg_data[:, 2]  # Column 2 = ECG\n        \n        # Load labels\n        with open(pkl_file, \"rb\") as f:\n            labels = pickle.load(f, encoding=\"latin1\")[\"label\"]\n        \n        # Ensure equal lengths\n        min_length = min(len(ecg_raw), len(labels))\n        ecg_raw = ecg_raw[:min_length]\n        labels = labels[:min_length]\n        \n        # Convert to mV\n        ecg_mv = ((ecg_raw / 65536) - 0.5) * 3.0\n        \n        # Create DataFrame\n        df = pd.DataFrame({\n            \"timestamp\": np.arange(min_length) / 700,\n            \"ecg_mv\": ecg_mv,\n            \"label\": labels,\n            \"subject_id\": subject_id\n        })\n        all_subjects_dfs.append(df)\n        print(f\"Processed {subject_id} | ECG: {len(ecg_raw)} | Labels: {len(labels)}\")\n        \n    except Exception as e:\n        print(f\"Error processing {subject_id}: {str(e)}\")\n\nif all_subjects_dfs:\n    combined_df = pd.concat(all_subjects_dfs, ignore_index=True)\n    print(f\"\\nSuccess! Combined DataFrame shape: {combined_df.shape}\")\n    print(\"Label distribution:\")\n    print(combined_df[\"label\"].value_counts())\nelse:\n    print(\"\\nNo valid data processed.\")","metadata":{"_uuid":"a88eaf4b-06e5-4f15-8f2d-6fe16003ce53","_cell_guid":"b626a29f-eb47-47eb-9a24-b53606981931","trusted":true,"execution":{"iopub.status.busy":"2025-04-04T22:16:55.159752Z","iopub.execute_input":"2025-04-04T22:16:55.160040Z","iopub.status.idle":"2025-04-04T22:18:43.046795Z","shell.execute_reply.started":"2025-04-04T22:16:55.160019Z","shell.execute_reply":"2025-04-04T22:18:43.045876Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# Assuming combined_df is already loaded\nvalid_df = combined_df[combined_df[\"label\"].isin([1, 2, 3])].copy()\nvalid_df[\"binary_label\"] = np.where(valid_df[\"label\"] == 2, 1, 0)\n\n# Get the counts\nbinary_counts = valid_df[\"binary_label\"].value_counts().sort_index()\n\n# Format the output\noutput = f\"Binary Label Distribution:\\n\" + \\\n         f\"0    {binary_counts[0]:>8}  # Non-stress (baseline + amusement)\\n\" + \\\n         f\"1    {binary_counts[1]:>8}  # Stress\\n\" + \\\n         f\"Name: binary_label, dtype: int64\"\n\nprint(output)","metadata":{"_uuid":"8ef63f0e-649b-4aaa-bc84-e0ab83577720","_cell_guid":"5fda1b23-3e0b-45c9-87a6-c6a5834e8d9e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-04T22:18:43.047958Z","iopub.execute_input":"2025-04-04T22:18:43.048212Z","iopub.status.idle":"2025-04-04T22:18:44.769250Z","shell.execute_reply.started":"2025-04-04T22:18:43.048191Z","shell.execute_reply":"2025-04-04T22:18:44.768126Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\n\n# 1. Display the first 5 rows of the DataFrame\nprint(\"Sample Data:\")\nprint(valid_df.head())\n\n# 2. Create the pie chart\nplt.figure(figsize=(8, 6))\n\n\n# Define labels and colors\nlabels = ['Non-stress (baseline + amusement)', 'Stress']\ncolors = ['#66b3ff', '#ff9999']\nexplode = (0.05, 0)  # Explode the 1st slice\n\nplt.pie(binary_counts, \n        labels=labels, \n        colors=colors,\n        autopct='%1.1f%%',\n        startangle=90,\n        explode=explode,\n        shadow=True)\n\nplt.title('Stress vs Non-Stress Distribution', fontsize=16)\nplt.axis('equal')  # Equal aspect ratio ensures pie is drawn as circle\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"9cc6d307-f5ac-4104-a988-dbc1049c78ba","_cell_guid":"9e2e0418-36bf-4616-a06e-233aa16e6c37","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-04T22:18:44.770902Z","iopub.execute_input":"2025-04-04T22:18:44.771274Z","iopub.status.idle":"2025-04-04T22:18:44.924385Z","shell.execute_reply.started":"2025-04-04T22:18:44.771240Z","shell.execute_reply":"2025-04-04T22:18:44.923537Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef create_labeled_windows(df, window_sec=60, sample_rate=700, min_agreement=0.75):\n    \"\"\"\n    Create labeled ECG windows from continuous data\n    \n    Parameters:\n        df: Input DataFrame with ECG data and labels\n        window_sec: Window length in seconds\n        sample_rate: Sampling rate in Hz\n        min_agreement: Minimum agreement threshold for label assignment\n        \n    Returns:\n        windows: ECG signal windows\n        labels: Corresponding labels\n    \"\"\"\n    window_size = window_sec * sample_rate\n    windows = []\n    labels = []\n    \n    for subject, subject_df in df.groupby('subject_id'):\n        ecg_signal = subject_df['ecg_mv'].values\n        binary_labels = subject_df['binary_label'].values\n        \n        for start in range(0, len(subject_df) - window_size + 1, window_size):\n            end = start + window_size\n            window_labels = binary_labels[start:end]\n            \n            label_counts = Counter(window_labels)\n            majority_label, majority_count = label_counts.most_common(1)[0]\n            agreement = majority_count / window_size\n            \n            if agreement >= min_agreement:\n                windows.append(ecg_signal[start:end])\n                labels.append(majority_label)\n    \n    return np.array(windows), np.array(labels)\n\n# Create windows\nwindows, labels = create_labeled_windows(valid_df)\n\n# Calculate statistics\ntotal_windows = len(windows)\nlabel_counts = pd.Series(labels).value_counts().sort_index()\nlabel_percent = label_counts / total_windows * 100\n\n# 1. Text Output\nprint(f\"\\n{'='*50}\")\nprint(f\"{'WINDOW STATISTICS':^50}\")\nprint(f\"{'='*50}\")\nprint(f\"\\nTotal windows created: {total_windows:,}\")\nprint(\"\\nLabel distribution:\")\nprint(f\"Non-stress (0): {label_counts.get(0, 0):,} windows ({label_percent.get(0, 0):.1f}%)\")\nprint(f\"Stress (1):     {label_counts.get(1, 0):,} windows ({label_percent.get(1, 0):.1f}%)\")\nprint(f\"\\nClass ratio: {label_counts.get(0, 1)/label_counts.get(1, 1):.2f}:1 (Non-stress:Stress)\")\n\n\n# Pie Chart\nplt.subplot(1, 3, 1)\nplt.pie(label_counts, \n        labels=['Non-stress', 'Stress'],\n        colors=['#4CAF50', '#F44336'],\n        radius=2,\n        autopct=lambda p: f'{p:.1f}%\\n({int(p/100*total_windows):,})',\n        startangle=90,\n        textprops={'fontsize': 9})\nplt.title('Window Distribution', pad=40)\n\n\n\n\nplt.show()","metadata":{"_uuid":"720e34b5-c887-46db-8434-353d7b20b891","_cell_guid":"6d4aa870-4ab0-4997-8ca7-85b9afc3765c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-04T22:18:44.925966Z","iopub.execute_input":"2025-04-04T22:18:44.926301Z","iopub.status.idle":"2025-04-04T22:18:50.271921Z","shell.execute_reply.started":"2025-04-04T22:18:44.926269Z","shell.execute_reply":"2025-04-04T22:18:50.271059Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install neurokit2","metadata":{"_uuid":"45ca6ded-5083-4744-bb0e-debc60e5904f","_cell_guid":"39f43c4a-c4af-4977-ba38-ebc45071190e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-04T22:18:50.272965Z","iopub.execute_input":"2025-04-04T22:18:50.273280Z","iopub.status.idle":"2025-04-04T22:18:53.847788Z","shell.execute_reply.started":"2025-04-04T22:18:50.273250Z","shell.execute_reply":"2025-04-04T22:18:53.846724Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install entropy","metadata":{"_uuid":"bf0a6b5b-7c97-4d3a-9e0f-63c58e940eb6","_cell_guid":"cdcfae5a-b8a0-4d36-8fe3-58ca19608579","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-04T22:18:53.849068Z","iopub.execute_input":"2025-04-04T22:18:53.849484Z","iopub.status.idle":"2025-04-04T22:18:57.623270Z","shell.execute_reply.started":"2025-04-04T22:18:53.849425Z","shell.execute_reply":"2025-04-04T22:18:57.621998Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport neurokit2 as nk\nfrom tqdm import tqdm\n\ndef calculate_hr(peaks, sampling_rate):\n    \"\"\"Robust heart rate calculation\"\"\"\n    if len(peaks['ECG_R_Peaks']) < 2:\n        return np.nan\n    rr_intervals = np.diff(peaks['ECG_R_Peaks']) / sampling_rate\n    return float(60 / np.mean(rr_intervals))\n\ndef extract_ecg_features(ecg_signal, sampling_rate=700):\n    \"\"\"Optimized feature extraction with guaranteed numeric output\"\"\"\n    try:\n        # 1. Preprocessing\n        cleaned = nk.ecg_clean(ecg_signal, sampling_rate=sampling_rate)\n        \n        # 2. Peak detection\n        peaks = nk.ecg_peaks(cleaned, sampling_rate=sampling_rate, method=\"kalidas2017\")[1]\n        \n        # 3. Feature extraction\n        features = {\n            # Basic ECG stats (always available)\n            'ecg_mean': float(np.mean(cleaned)),\n            'ecg_std': float(np.std(cleaned)),\n            'ecg_skew': float(pd.Series(cleaned).skew()),\n            'ecg_kurtosis': float(pd.Series(cleaned).kurtosis()),\n            \n            # Heart rate (fixed calculation)\n            'hr_mean': calculate_hr(peaks, sampling_rate),\n        }\n        \n        # 4. HRV features (only if enough peaks)\n        if len(peaks['ECG_R_Peaks']) > 4:\n            hrv_time = nk.hrv_time(peaks, sampling_rate=sampling_rate)\n            hrv_freq = nk.hrv_frequency(peaks, sampling_rate=sampling_rate)\n            \n            features.update({\n                'hrv_sdnn': float(hrv_time['HRV_SDNN'].iloc[0]),\n                'hrv_rmssd': float(hrv_time['HRV_RMSSD'].iloc[0]),\n                'hrv_pnn50': float(hrv_time['HRV_pNN50'].iloc[0]),\n                'hrv_hf': float(hrv_freq['HRV_HF'].iloc[0]),\n                'hrv_lf': float(hrv_freq['HRV_LF'].iloc[0]),\n                'hrv_lfhf': float(hrv_freq['HRV_LFHF'].iloc[0])\n            })\n        \n        return features\n        \n    except Exception as e:\n        print(f\"Error in feature extraction: {str(e)}\")\n        return None\n\ndef process_all_windows(windows, labels, sampling_rate=700):\n    \"\"\"\n    Process all ECG windows and create feature matrix\n    \n    Parameters:\n        windows (list): List of ECG window arrays\n        labels (array): Corresponding labels\n        sampling_rate (int): Sampling frequency in Hz\n        \n    Returns:\n        DataFrame: Features with labels\n    \"\"\"\n    features = []\n    for i in tqdm(range(len(windows)), desc=\"Extracting Features\"):\n        feat = extract_ecg_features(windows[i], sampling_rate)\n        if feat is not None:  # Only append if feature extraction succeeded\n            feat['label'] = labels[i]\n            features.append(feat)\n    \n    return pd.DataFrame(features).fillna(method='ffill')\n\n# Example usage (assuming you have windows and labels defined)\nif __name__ == \"__main__\":\n    # You'll need to define these variables first:\n    # windows = [your_ecg_data_arrays]\n    # labels = [corresponding_labels]\n    \n    feature_df = process_all_windows(windows, labels)\n\n    # Display final results\n    print(\"\\n\" + \"=\"*50)\n    print(f\"{'FINAL FEATURE EXTRACTION RESULTS':^50}\")\n    print(\"=\"*50)\n    print(f\"\\nTotal windows processed: {len(feature_df)}\")\n    print(f\"Success rate: {100*(1-feature_df.isna().mean().mean()):.1f}%\")\n    print(\"\\nLabel distribution:\")\n    print(feature_df['label'].value_counts())\n    print(\"\\nFeature preview (no NaN values):\")\n    print(feature_df.dropna().head(3).to_string(float_format=\"%.3f\"))","metadata":{"_uuid":"c97a3d2a-78bd-41dc-8bab-f2d8839c776f","_cell_guid":"06095b6b-8e14-4092-9fc0-04297f5f401d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-04T22:18:57.625042Z","iopub.execute_input":"2025-04-04T22:18:57.625400Z","iopub.status.idle":"2025-04-04T22:19:11.248149Z","shell.execute_reply.started":"2025-04-04T22:18:57.625354Z","shell.execute_reply":"2025-04-04T22:19:11.247283Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Display first 5 rows with formatted floats\npd.set_option('display.float_format', '{:.3f}'.format)\ndisplay(feature_df.head().style.set_caption(\"First 5 Windows with Extracted Features\"))","metadata":{"_uuid":"b7a9a3e1-ccd6-455a-b6cd-83b78f735e65","_cell_guid":"328d6116-7b1f-4233-9e1f-b5d1cbfe0825","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-04T22:19:11.251074Z","iopub.execute_input":"2025-04-04T22:19:11.251388Z","iopub.status.idle":"2025-04-04T22:19:11.260262Z","shell.execute_reply.started":"2025-04-04T22:19:11.251357Z","shell.execute_reply":"2025-04-04T22:19:11.259428Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport pandas as pd\n\n# Separate data into stress (1) and non-stress (0)\nstress = feature_df[feature_df['label'] == 1]\nnon_stress = feature_df[feature_df['label'] == 0]\n\n# Split each class separately (70% train, 30% test)\nX_stress_train, X_stress_test, y_stress_train, y_stress_test = train_test_split(\n    stress.drop(columns=['label']), \n    stress['label'], \n    test_size=0.3, \n    random_state=42\n)\n\nX_non_stress_train, X_non_stress_test, y_non_stress_train, y_non_stress_test = train_test_split(\n    non_stress.drop(columns=['label']), \n    non_stress['label'], \n    test_size=0.3, \n    random_state=42\n)\n\n# Combine the splits\nX_train = pd.concat([X_stress_train, X_non_stress_train], axis=0)\ny_train = pd.concat([y_stress_train, y_non_stress_train], axis=0)\n\nX_test = pd.concat([X_stress_test, X_non_stress_test], axis=0)\ny_test = pd.concat([y_stress_test, y_non_stress_test], axis=0)\n\n# Verify distribution\nprint(\"Original Class Counts:\")\nprint(f\"Non-stress (0): {len(non_stress)}\")\nprint(f\"Stress (1): {len(stress)}\")\n\nprint(\"\\nTrain Set Distribution:\")\nprint(y_train.value_counts())\nprint(f\"Ratio: {y_train.mean():.3f}\")\n\nprint(\"\\nTest Set Distribution:\")\nprint(y_test.value_counts())\nprint(f\"Ratio: {y_test.mean():.3f}\")\n\n# Shuffle the datasets (important for training)\nX_train = X_train.sample(frac=1, random_state=42)\ny_train = y_train.loc[X_train.index]\n\nX_test = X_test.sample(frac=1, random_state=42)\ny_test = y_test.loc[X_test.index]","metadata":{"_uuid":"2249ca52-6d8d-4055-91b0-bc0b60497749","_cell_guid":"0c31ff70-d722-4503-878e-dafb2ec06ec5","trusted":true,"execution":{"iopub.status.busy":"2025-04-04T22:19:11.261402Z","iopub.execute_input":"2025-04-04T22:19:11.261695Z","iopub.status.idle":"2025-04-04T22:19:11.289023Z","shell.execute_reply.started":"2025-04-04T22:19:11.261670Z","shell.execute_reply":"2025-04-04T22:19:11.288232Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\n# Apply SMOTE with 1:1 ratio\nsmote = SMOTE(\n    sampling_strategy=1.0,  # Force exact balance (263:263)\n    k_neighbors=5,          # Optimal for ECG feature space\n    random_state=42\n)\nX_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n\n# Verify\nprint(\"\\nAfter SMOTE:\")\nprint(pd.Series(y_train_smote).value_counts())\nprint(f\"New ratio: {y_train_smote.mean():.1%}\")","metadata":{"_uuid":"1a4bd415-4221-4824-9b70-5087dd8e6d78","_cell_guid":"2b604c5d-7d15-42ab-870d-a57c39cecb70","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-04T22:19:11.290011Z","iopub.execute_input":"2025-04-04T22:19:11.290285Z","iopub.status.idle":"2025-04-04T22:19:11.303394Z","shell.execute_reply.started":"2025-04-04T22:19:11.290258Z","shell.execute_reply":"2025-04-04T22:19:11.302659Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n\nmodel = RandomForestClassifier(\n    n_estimators=150,\n    max_depth=9,\n    class_weight='balanced',\n    random_state=42\n)\nmodel.fit(X_train_smote, y_train_smote)\n#model.fit(X_train, y_train)\n# Make predictions\ny_pred = model.predict(X_test)\n\n# Accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Model Accuracy: {accuracy:.2%}\")\nprint(\"\\nDetailed Report:\")\nprint(classification_report(y_test, y_pred, target_names=[\"Non-stress\", \"Stress\"]))\n\n# 3. Confusion Matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\nConfusionMatrixDisplay.from_predictions(y_test, y_pred, \n                                      display_labels=[\"Non-stress\", \"Stress\"],\n                                      cmap='Blues')\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"_uuid":"0298a73a-164d-45fd-9ce8-439503beb3c9","_cell_guid":"67408a5d-21e4-4aef-ad1e-daca1449bf57","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-04T23:25:12.138682Z","iopub.execute_input":"2025-04-04T23:25:12.138985Z","iopub.status.idle":"2025-04-04T23:25:12.572696Z","shell.execute_reply.started":"2025-04-04T23:25:12.138964Z","shell.execute_reply":"2025-04-04T23:25:12.571982Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\n\n# 1. Predict probabilities for the positive class (Stress = 1)\ny_proba = model.predict_proba(X_test)[:, 1]\n\n# 2. Compute ROC curve and ROC area\nfpr, tpr, thresholds = roc_curve(y_test, y_proba)\nroc_auc = auc(fpr, tpr)\n\n# 3. Plot the ROC curve\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Chance')\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc='lower right')\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T23:37:29.058199Z","iopub.execute_input":"2025-04-04T23:37:29.058554Z","iopub.status.idle":"2025-04-04T23:37:29.251692Z","shell.execute_reply.started":"2025-04-04T23:37:29.058525Z","shell.execute_reply":"2025-04-04T23:37:29.250807Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\n# 1. Initialize and train Decision Tree\ndt_model = DecisionTreeClassifier(\n    max_depth=10,                # Limit tree depth to 5\n    criterion='entropy',        # Use entropy for information gain\n    class_weight='balanced',    # Handle class imbalance\n    random_state=42\n)\ndt_model.fit(X_train_smote, y_train_smote)\n# 2. Evaluate\ny_pred = dt_model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(f\"Decision Tree Accuracy: {accuracy:.2%}\")\nprint(\"\\nDetailed Report:\")\nprint(classification_report(y_test, y_pred, target_names=[\"Non-stress\", \"Stress\"]))\n\n# 3. Confusion Matrix\nConfusionMatrixDisplay.from_predictions(\n    y_test, y_pred,\n    display_labels=[\"Non-stress\", \"Stress\"],\n    cmap='Blues'\n)\nplt.title(\"Decision Tree Confusion Matrix\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T23:33:10.824128Z","iopub.execute_input":"2025-04-04T23:33:10.824424Z","iopub.status.idle":"2025-04-04T23:33:10.997582Z","shell.execute_reply.started":"2025-04-04T23:33:10.824401Z","shell.execute_reply":"2025-04-04T23:33:10.996613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay, roc_auc_score\nimport matplotlib.pyplot as plt\n\n# 1. Initialize and train XGBoost with balanced classes\nxgb_model = XGBClassifier(\n    max_depth=5,               # Control tree depth\n    learning_rate=0.1,         # Shrinkage to prevent overfitting\n    n_estimators=150,          # Number of boosting rounds\n    scale_pos_weight=2.375,    # Counter class imbalance (48 stress / 114 non-stress ≈ 2.375)\n    objective='binary:logistic',\n    eval_metric='logloss',     # Alternative: 'auc'\n    random_state=42\n)\n\n# Train the model with SMOTE-augmented data\nxgb_model.fit(X_train_smote, y_train_smote)\n\n# 2. Evaluate the model\ny_pred_xgb = xgb_model.predict(X_test)\n\n# Accuracy\naccuracy_xgb = accuracy_score(y_test, y_pred_xgb)\nprint(f\"XGBoost Model Accuracy: {accuracy_xgb:.2%}\")\nprint(\"\\nDetailed Classification Report:\")\nprint(classification_report(y_test, y_pred_xgb, target_names=[\"Non-stress\", \"Stress\"]))\n\n# 3. Confusion Matrix\nConfusionMatrixDisplay.from_predictions(y_test, y_pred_xgb, \n                                         display_labels=[\"Non-stress\", \"Stress\"],\n                                         cmap='Blues')\nplt.title(\"XGBoost Confusion Matrix\")\nplt.show()\n\n# 4. Calculate AUC (Area Under the Curve)\nroc_auc_xgb = roc_auc_score(y_test, xgb_model.predict_proba(X_test_scaled)[:, 1])\nprint(f\"AUC: {roc_auc_xgb:.2%}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T23:52:32.150812Z","iopub.execute_input":"2025-04-04T23:52:32.151117Z","iopub.status.idle":"2025-04-04T23:52:32.430465Z","shell.execute_reply.started":"2025-04-04T23:52:32.151094Z","shell.execute_reply":"2025-04-04T23:52:32.429028Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\n\n# Fit scaler ONLY on training data\nscaler = RobustScaler().fit(X_train_smote)  # Use SMOTE-augmented data\nX_train_scaled = scaler.transform(X_train_smote)\nX_test_scaled = scaler.transform(X_test)  # Transform test set with same scaler\n\n# Verify no data leakage\nprint(f\"Test set scaled (sample):\\n{X_test_scaled[0,:5].round(2)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T22:42:05.901006Z","iopub.execute_input":"2025-04-04T22:42:05.901328Z","iopub.status.idle":"2025-04-04T22:42:05.914599Z","shell.execute_reply.started":"2025-04-04T22:42:05.901301Z","shell.execute_reply":"2025-04-04T22:42:05.913863Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n\n# Initialize and train the SVM model\nsvm_model = SVC(kernel='rbf', C=32, gamma='scale', probability=True, random_state=42)  # Adjust C, gamma if needed\nsvm_model.fit(X_train_scaled, y_train_smote)\n\n# Make predictions\ny_pred_svm = svm_model.predict(X_test_scaled)\n\n# Evaluate the model\naccuracy_svm = accuracy_score(y_test, y_pred_svm)\nprint(f\"SVM Model Accuracy: {accuracy_svm:.2%}\")\nprint(\"\\nDetailed Classification Report:\")\nprint(classification_report(y_test, y_pred_svm, target_names=[\"Non-stress\", \"Stress\"]))\n\n# Calculate AUC\nroc_auc_svm = roc_auc_score(y_test, svm_model.predict_proba(X_test_scaled)[:, 1])\nprint(f\"AUC: {roc_auc_svm:.2%}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T23:49:55.545986Z","iopub.execute_input":"2025-04-04T23:49:55.546273Z","iopub.status.idle":"2025-04-04T23:49:55.608928Z","shell.execute_reply.started":"2025-04-04T23:49:55.546251Z","shell.execute_reply":"2025-04-04T23:49:55.608060Z"}},"outputs":[],"execution_count":null}]}